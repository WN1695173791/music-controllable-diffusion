
Training GMVAE
Training --> GMIWVae(
  (_encoder): Encoder(
    (_net): Sequential(
      (0): Linear(in_features=784, out_features=392, bias=True)
      (1): ReLU()
      (2): Linear(in_features=392, out_features=196, bias=True)
      (3): Tanh()
      (4): Linear(in_features=196, out_features=196, bias=True)
      (5): ReLU()
      (6): Linear(in_features=196, out_features=98, bias=True)
    )
    (_fc_mean): Sequential(
      (0): Linear(in_features=98, out_features=20, bias=True)
    )
    (_fc_log_var): Sequential(
      (0): Linear(in_features=98, out_features=20, bias=True)
    )
  )
  (_decoder): Decoder(
    (_net): Sequential(
      (0): Linear(in_features=20, out_features=196, bias=True)
      (1): ReLU()
      (2): Linear(in_features=196, out_features=392, bias=True)
      (3): Tanh()
      (4): Linear(in_features=392, out_features=392, bias=True)
      (5): ReLU()
      (6): Linear(in_features=392, out_features=784, bias=True)
      (7): Sigmoid()
    )
  )
)
====> Train Loss = -570800440.7296 Epoch = 1
====> Train Loss = -571005765.7002667 Epoch = 2
====> Train Loss = -571005901.824 Epoch = 3
====> Train Loss = -571005909.9477333 Epoch = 4
====> Train Loss = -571005908.2410667 Epoch = 5
====>  Test Loss = -73541182710.27849
====> Train Loss = -571005907.6949333 Epoch = 6
====> Train Loss = -571005910.4938667 Epoch = 7
====> Train Loss = -571005911.3130667 Epoch = 8
====> Train Loss = -571005910.6986667 Epoch = 9
====> Train Loss = -571005910.2890667 Epoch = 10
