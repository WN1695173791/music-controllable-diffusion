
Training GMVAE
Traceback (most recent call last):
  File "/home/joy/.local/share/JetBrains/Toolbox/apps/PyCharm-P/ch-0/212.5457.59/plugins/python/helpers/pydev/pydevd.py", line 1483, in _exec
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File "/home/joy/.local/share/JetBrains/Toolbox/apps/PyCharm-P/ch-0/212.5457.59/plugins/python/helpers/pydev/_pydev_imps/_pydev_execfile.py", line 18, in execfile
    exec(compile(contents+"\n", file, 'exec'), glob, loc)
  File "/home/joy/projects/music-controllable-diffusion/models/gmiw_vae/gmiw_vae.py", line 144, in <module>
    model.fit(epoch, _optimizer)
  File "/home/joy/projects/music-controllable-diffusion/models/base/base_model.py", line 101, in fit
    loss = self.step(batch, batch_idx)
  File "/home/joy/projects/music-controllable-diffusion/models/gmiw_vae/gmiw_vae.py", line 106, in step
    loss = self.forward(batch)
  File "/home/joy/projects/music-controllable-diffusion/models/gmiw_vae/gmiw_vae.py", line 102, in forward
    niwae, kl, rec = self.negative_iwae_bound(x, iw=1000)
  File "/home/joy/projects/music-controllable-diffusion/models/gmiw_vae/gmiw_vae.py", line 81, in negative_iwae_bound
    z_weighted_priors = ut.log_normal_mixture(z, weighted_p_m, weighted_p_v)
  File "/home/joy/projects/music-controllable-diffusion/utils/model_utils.py", line 92, in log_normal_mixture
    log_probs = compute_log_prob(m_z, m, v)
  File "/home/joy/projects/music-controllable-diffusion/utils/model_utils.py", line 41, in compute_log_prob
    log_probs = -1 * torch.pow((x - m), 2) / (2 * v) - const - log_std
RuntimeError: CUDA out of memory. Tried to allocate 4.77 GiB (GPU 0; 23.70 GiB total capacity; 15.81 GiB already allocated; 4.04 GiB free; 15.84 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
Training --> GMIWVae(
  (_encoder): Encoder(
    (_net): Sequential(
      (0): Linear(in_features=784, out_features=392, bias=True)
      (1): ReLU()
      (2): Linear(in_features=392, out_features=196, bias=True)
      (3): Tanh()
      (4): Linear(in_features=196, out_features=196, bias=True)
      (5): ReLU()
      (6): Linear(in_features=196, out_features=98, bias=True)
    )
    (_fc_mean): Sequential(
      (0): Linear(in_features=98, out_features=20, bias=True)
    )
    (_fc_log_var): Sequential(
      (0): Linear(in_features=98, out_features=20, bias=True)
    )
  )
  (_decoder): Decoder(
    (_net): Sequential(
      (0): Linear(in_features=20, out_features=196, bias=True)
      (1): ReLU()
      (2): Linear(in_features=196, out_features=392, bias=True)
      (3): Tanh()
      (4): Linear(in_features=392, out_features=392, bias=True)
      (5): ReLU()
      (6): Linear(in_features=392, out_features=784, bias=True)
      (7): Sigmoid()
    )
  )
